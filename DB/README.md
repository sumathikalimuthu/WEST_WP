
# SEO WestWP â€“ Automated SEO Analysis & Weekly Reporting System

SEO WestWP is an automated SEO system that collects data from
Google Search Console (GSC) and Google Analytics 4 (GA4),
processes it using Celery,
analyzes SEO issues using Gemini AI,
generates weekly PDF SEO reports,
and sends them automatically via Brevo (Sendinblue) email.

Daily data is fetched automatically.
Weekly SEO reports are generated and emailed.

---

## What this project does

**Daily**
  - Fetch GSC data
  - Fetch GA4 data
  - Send raw data email

**Weekly**
  - Clean and merge data
  - Gemini AI SEO analysis
  - Generate PDF report
  - Send PDF via Brevo email

---

## Tech stack

Python
Celery + Celery Beat
Pandas
Google Search Console API
Google Analytics 4 API
Gemini AI
Brevo SMTP (Sendinblue)
PDF generation
FastAPI (Uvicorn)
Redis / RabbitMQ

---

## Prerequisites

Python 3.10+
pip
Redis or RabbitMQ running
Google Service Account (GSC + GA4 access)
Brevo SMTP credentials

---

## Project Structure (with comments)

text
FINAL/
â”‚
â”œâ”€â”€ DB/                         # Raw & processed SEO data
â”œâ”€â”€ output/                     # Daily fetched raw outputs
â”œâ”€â”€ preprocessed_outputs/       # Weekly cleaned & merged data
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ preprocessing.py        # Weekly data cleaning & merging
â”‚
â”œâ”€â”€ reports/                    # Generated weekly PDF reports
â”‚
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ seo_tasks.py            # Fetch, preprocess, AI, email tasks
â”‚   â””â”€â”€ pdf_tasks.py            # PDF generation tasks
â”‚
â”œâ”€â”€ celery_app.py               # Main Celery app (seo_reports queue)
â”œâ”€â”€ celery_pdf_app.py           # PDF Celery app (seo_pdf_reports queue)
â”‚
â”œâ”€â”€ ga4_utils.py                # GA4 API logic
â”œâ”€â”€ gsc_utils.py                # GSC API logic
â”œâ”€â”€ pdf_utils.py                # PDF helper functions
â”œâ”€â”€ send_email.py               # Brevo email logic
â”‚
â”œâ”€â”€ main.py                     # FastAPI entry point
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ service_account.json        # Google API credentials
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ .env                        # Environment variables (DO NOT COMMIT)
### ğŸ›  Installation & Setup

### 1ï¸âƒ£ Clone the repository
bash
git clone <your_repo_url>
cd FINAL


# Create virtual environment
python -m venv venv

# Activate virtual environment

# Windows
venv\Scripts\activate

# Linux / macOS
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
# 1. Start main Celery worker
# Fetch data, preprocessing, AI analysis, email
celery -A celery_app worker --loglevel=info --pool=solo -Q seo_reports

# 2. Start Celery Beat
# Schedules daily & weekly jobs
celery -A celery_app beat --loglevel=info

# 3. Start PDF worker
# Handles only PDF generation
celery -A celery_pdf_app.celery_pdf_app worker -Q seo_pdf_reports -l info --concurrency=1 --pool=solo

# 4. Run FastAPI server
# API access & monitoring
uvicorn main:app --reload